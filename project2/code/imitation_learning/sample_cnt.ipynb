{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.utils import seed_everything, create_dataset_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2080/2080 [01:38<00:00, 21.19it/s]\n"
     ]
    }
   ],
   "source": [
    "obses, samples = create_dataset_from_json('/Disk3/yiming/episodes/1800/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [sample[-1] for sample in samples]\n",
    "train, val = train_test_split(\n",
    "        samples, test_size=0.1, random_state=0, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994128 221570\n"
     ]
    }
   ],
   "source": [
    "print(len(train),len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['train']=train\n",
    "samples['val']=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/obses.pkl\",'wb') as f:\n",
    "    pickle.dump(obses,f)\n",
    "with open(\"./data/train_1800.pkl\",'wb') as f:\n",
    "    pickle.dump(train,f)\n",
    "with open(\"./data/val_1800.pkl\",'wb') as f:\n",
    "    pickle.dump(val,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保证不同map_size的sample个数大致相同\n",
    "map_cnt = {\n",
    "    'train':{},\n",
    "    'val':{}\n",
    "}\n",
    "for k,v in samples.items():\n",
    "    for obs_id, unit_id, action in v:\n",
    "        map_size = obses[obs_id]['width']\n",
    "        if not map_size in map_cnt[k].keys():\n",
    "            map_cnt[k][map_size] = 0\n",
    "        map_cnt[k][map_size]+=1\n",
    "print(map_cnt)\n",
    "train_cnt=min(map_cnt['train'].values())\n",
    "val_cnt=min(map_cnt['val'].values())\n",
    "print(train_cnt,val_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "samples_dict={\n",
    "    'train':{12:[],16:[],24:[],32:[]},\n",
    "    'val':{12:[],16:[],24:[],32:[]}\n",
    "}\n",
    "for k,v in samples.items():\n",
    "    for sample in tqdm(v):\n",
    "        obs_id, unit_id, action=sample\n",
    "        map_size = obses[obs_id]['width']\n",
    "        samples_dict[k][map_size].append(sample)\n",
    "for k,v in samples_dict.items():\n",
    "    for key,value in v.items():\n",
    "        print(k,key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sample_cnt={'train':train_cnt,'val':val_cnt}\n",
    "for k,v in samples_dict.items():\n",
    "    for key,value in v.items():\n",
    "        samples_dict[k][key]=random.sample(value,sample_cnt[k])\n",
    "\n",
    "for k,v in samples_dict.items():\n",
    "    for key,value in v.items():\n",
    "        print(k,key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample,val_sample=[],[]\n",
    "for key,value in samples_dict['train'].items():\n",
    "    train_sample+=value\n",
    "for key,value in samples_dict['val'].items():\n",
    "    val_sample+=value\n",
    "print(len(train_sample))\n",
    "print(len(val_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_sample[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open(\"./data/obses.pkl\",'wb') as f:\n",
    "#     pickle.dump(obses,f)\n",
    "with open(\"./data/train.pkl\",'wb') as f:\n",
    "    pickle.dump(train_sample,f)\n",
    "with open(\"./data/val.pkl\",'wb') as f:\n",
    "    pickle.dump(val_sample,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/train.pkl\",'rb') as f:\n",
    "    train_sample=pickle.load(f)\n",
    "with open(\"./data/val.pkl\",'rb') as f:\n",
    "    val_sample=pickle.load(f)\n",
    "with open(\"./data/obses.pkl\",'rb') as f:\n",
    "    obses=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个step的sample数量也要大致相同\n",
    "train_sample_step={}\n",
    "for sample in train_sample:\n",
    "    obs_id, unit_id, action=sample\n",
    "    obs=obses[obs_id]\n",
    "    step=obs['step']\n",
    "    if not step in train_sample_step.keys():\n",
    "        train_sample_step[step]=[]\n",
    "    train_sample_step[step].append(sample)\n",
    "for k,v in sorted(train_sample_step.items(),key=lambda x: x[0]):\n",
    "    print(k,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mean=int(np.mean([len(v) for v in train_sample_step.values()]))\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for k,v in train_sample_step.items():\n",
    "    train_sample_step[k]=random.sample(v,min(len(v),mean))\n",
    "for k,v in sorted(train_sample_step.items(),key=lambda x: x[0]):\n",
    "    print(k,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample=[]\n",
    "for k,v in train_sample_step.items():\n",
    "    train_sample+=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train.pkl\",'wb') as f:\n",
    "    pickle.dump(train_sample,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=val_sample+train_sample\n",
    "cnt=[0,0,0,0,0]\n",
    "for obs_id, unit_id, label in tqdm(samples):\n",
    "    cnt[label]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=[i*-1 for i in cnt]\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=np.array(cnt)/np.abs(np.mean(cnt))\n",
    "print(cnt)\n",
    "cnt_exp=np.exp2(cnt)\n",
    "sum=np.sum(cnt_exp)\n",
    "print(sum)\n",
    "cnt_exp=cnt_exp/sum*10\n",
    "cnt_exp/min(cnt_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cnt=[0]*360\n",
    "for obs_id, unit_id, label in tqdm(samples):\n",
    "    obs=obses[obs_id]\n",
    "    step=obs['step']\n",
    "    obs_cnt[step]+=1\n",
    "np.sum(obs_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.lux_dataset import make_input\n",
    "import pickle\n",
    "with open(\"./data/train.pkl\",'rb') as f:\n",
    "    train_sample=pickle.load(f)\n",
    "with open(\"./data/val.pkl\",'rb') as f:\n",
    "    val_sample=pickle.load(f)\n",
    "with open(\"./data/obses.pkl\",'rb') as f:\n",
    "    obses=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs_id, unit_id, label in train_sample:\n",
    "    obs=obses[obs_id]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c156225d649cdcab61d2beb93b7f2b03b859aa444dbacadf1aba4c6b276e13f8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('torch_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
